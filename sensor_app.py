import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_squared_error

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Sensor ML Expert", layout="wide")

st.title("ğŸ§ª ì„¼ì„œ ì •ë°€ ë¶„ì„: ìˆ˜ì‹ ë° ë³€ìˆ˜ ì¤‘ìš”ë„ í¬í•¨")
st.markdown("ì•Œê³ ë¦¬ì¦˜ë³„ë¡œ **ìˆ˜ì‹** ë˜ëŠ” **ë³€ìˆ˜ ì¤‘ìš”ë„**ë¥¼ í™•ì¸í•˜ì—¬ ì„¼ì„œ íŠ¹ì„±ì„ íŒŒì•…í•˜ì„¸ìš”.")

# 2. ì‚¬ì´ë“œë°” - ëª¨ë¸ ì„ íƒ
st.sidebar.header("ğŸ¤– ëª¨ë¸ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ")
model_choice = st.sidebar.selectbox(
    "ì ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
    [
        "1. ì„ í˜• íšŒê·€ (Linear Regression)", 
        "2. ë¦¿ì§€ íšŒê·€ (Ridge Regression)", 
        "3. ì˜ì‚¬ê²°ì • ë‚˜ë¬´ (Decision Tree)", 
        "4. ëœë¤ í¬ë ˆìŠ¤íŠ¸ (Random Forest)", 
        "5. ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… (Gradient Boosting)"
    ]
)

# 3. íŒŒì¼ ì—…ë¡œë”
uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—¬ê¸°ì— ë“œë˜ê·¸í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”", type="csv")

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    df.columns = [col.strip() for col in df.columns]
    if 'ì¸¡ì • ì‹œê°„' in df.columns:
        df['ì¸¡ì • ì‹œê°„'] = pd.to_datetime(df['ì¸¡ì • ì‹œê°„'])
    df['Resistance_kOhm'] = df['ì €í•­'] / 1000.0
    
    X = df[['ì˜¨ë„', 'ìŠµë„']]
    y = df['Resistance_kOhm']
    
    # --- ê¸°ì´ˆ ì„ í˜• ê³µì‹ ì‚°ì¶œ (ì°¸ê³ ìš©ìœ¼ë¡œ í•­ìƒ ê³„ì‚°) ---
    base_model = LinearRegression().fit(X, y)
    base_intercept = base_model.intercept_
    base_t_coef = base_model.coef_[0]
    base_h_coef = base_model.coef_[1]

    # --- ì„ íƒëœ ëª¨ë¸ í•™ìŠµ ---
    if "1." in model_choice:
        model = LinearRegression()
    elif "2." in model_choice:
        model = Ridge(alpha=1.0)
    elif "3." in model_choice:
        model = DecisionTreeRegressor(max_depth=10)
    elif "4." in model_choice:
        model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)
    elif "5." in model_choice:
        model = GradientBoostingRegressor(n_estimators=50, random_state=42)

    with st.spinner(f'{model_choice} ë¶„ì„ ì¤‘...'):
        model.fit(X, y)
    
    y_pred = model.predict(X)
    r2 = r2_score(y, y_pred)
    rmse = np.sqrt(mean_squared_error(y, y_pred))

    # 4. ëª¨ë¸ ë¶„ì„ ê²°ê³¼ (ìˆ˜ì‹ ë˜ëŠ” ì¤‘ìš”ë„)
    st.divider()
    st.header(f"ğŸ“Š ëª¨ë¸ ë¶„ì„ ë¦¬í¬íŠ¸: {model_choice.split('. ')[1]}")
    
    col_info1, col_info2 = st.columns([2, 1])
    
    with col_info1:
        # ì„ í˜• ê¸°ë°˜ ëª¨ë¸ì¼ ê²½ìš° ìˆ˜ì‹ ì¶œë ¥
        if hasattr(model, 'coef_'):
            st.subheader("ğŸ“ ëª¨ë¸ íšŒê·€ ê³µì‹ (Regression Formula)")
            st.info(f"**$R(k\Omega) = {model.intercept_:.2f} + ({model.coef_[0]:.4f} \\times T) + ({model.coef_[1]:.4f} \\times H)$**")
        else:
            # ë¹„ì„ í˜• ëª¨ë¸ì¼ ê²½ìš° ë³€ìˆ˜ ì¤‘ìš”ë„ ì¶œë ¥
            st.subheader("ğŸ’¡ ë³€ìˆ˜ ì¤‘ìš”ë„ (Feature Importance)")
            importances = model.feature_importances_
            feat_imp = pd.Series(importances, index=['ì˜¨ë„(Temp)', 'ìŠµë„(Humi)'])
            
            fig_imp, ax_imp = plt.subplots(figsize=(6, 2))
            feat_imp.plot(kind='barh', color=['red', 'blue'], ax=ax_imp)
            ax_imp.set_title("Which factor is more important?")
            st.pyplot(fig_imp)
            st.write(f"ì´ ëª¨ë¸ì€ ì €í•­ì„ ì˜ˆì¸¡í•  ë•Œ **ì˜¨ë„ë¥¼ {importances[0]*100:.1f}%**, **ìŠµë„ë¥¼ {importances[1]*100:.1f}%** ë¹„ì¤‘ìœ¼ë¡œ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤.")

    with col_info2:
        st.subheader("ğŸ¯ ëª¨ë¸ ì„±ëŠ¥")
        st.metric("ê²°ì •ê³„ìˆ˜ (RÂ²)", f"{r2:.4f}")
        st.metric("í‰ê·  ì˜¤ì°¨ (RMSE)", f"{rmse:.4f} kÎ©")

    # 5. ì‹¤ì‹œê°„ ì‹œë®¬ë ˆì´í„°
    st.divider()
    st.header("ğŸ” ì‹¤ì‹œê°„ ì €í•­ ì˜ˆì¸¡")
    c_in1, c_in2, c_res = st.columns([1, 1, 2])
    with c_in1:
        input_temp = st.number_input("í˜„ì¬ ì˜¨ë„ (Â°C)", value=float(df['ì˜¨ë„'].mean()))
    with c_in2:
        input_humi = st.number_input("í˜„ì¬ ìŠµë„ (%)", value=float(df['ìŠµë„'].mean()))
    
    pred_val = model.predict([[input_temp, input_humi]])[0]
    with c_res:
        st.metric(f"ì˜ˆì¸¡ ì €í•­ê°’ ({model_choice.split('. ')[1]})", f"{pred_val:.4f} kÎ©")

    # 6. ì‹œê°í™” (4ë‹¨ ê·¸ë˜í”„ - ì˜ë¬¸)
    st.divider()
    plt.rcdefaults()
    sns.set_theme(style="whitegrid")
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    sns.regplot(ax=axes[0, 0], x='ì˜¨ë„', y='Resistance_kOhm', data=df, scatter_kws={'alpha': 0.03, 's': 1}, line_kws={'color': 'red'})
    axes[0, 0].set_title("Temperature vs Resistance")

    sns.regplot(ax=axes[0, 1], x='ìŠµë„', y='Resistance_kOhm', data=df, scatter_kws={'alpha': 0.03, 's': 1}, line_kws={'color': 'blue'})
    axes[0, 1].set_title("Humidity vs Resistance")

    axes[1, 0].scatter(y, y_pred, alpha=0.1, s=1, color='purple')
    axes[1, 0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
    axes[1, 0].set_title(f"Model Linearity (R2={r2:.4f})")

    sample_df = df.iloc[::25]
    axes[1, 1].plot(sample_df['ì¸¡ì • ì‹œê°„'], sample_df['Resistance_kOhm'], label='Actual', alpha=0.4, color='black')
    axes[1, 1].plot(sample_df['ì¸¡ì • ì‹œê°„'], y_pred[::25], label='Predicted', color='limegreen', linestyle='--')
    axes[1, 1].legend()
    axes[1, 1].set_title("Actual vs Predicted Over Time")

    plt.tight_layout()
    st.pyplot(fig)

    st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", df.to_csv(index=False).encode('utf-8'), "final_results.csv")

else:
    st.info("ğŸ‘‹ ë¶„ì„í•  ì„¼ì„œ ë°ì´í„° CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")