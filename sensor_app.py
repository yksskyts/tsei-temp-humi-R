import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ì‚¬ì´í‚·ëŸ° ëª¨ë¸ ëŒ€ê±° ì„í¬íŠ¸
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, HuberRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score, mean_squared_error

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Sensor ML Benchmarking", layout="wide")
st.title("ğŸ§ª ì‚¬ì´í‚·ëŸ° ì „ ëª¨ë¸ ë¹„êµ: ì„¼ì„œ ë¬¼ë¦¬ ëª¨ë¸ë§")
st.markdown("ëª¨ë“  ì£¼ìš” ML ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ì—¬ **ì ˆëŒ€ì˜¨ë„(K)**ì™€ **ìˆ˜ì¦ê¸° ë†ë„(ppm)**ì— ëŒ€í•œ ìµœì ì˜ ì˜ˆì¸¡ ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.")

# 2. ì‚¬ì´ë“œë°” ëª¨ë¸ ì„ íƒ (10ì¢…)
st.sidebar.header("ğŸ¤– ML ëª¨ë¸ ë²¤ì¹˜ë§ˆí‚¹")
model_dict = {
    "Linear Regression": LinearRegression(),
    "Ridge Regression": Ridge(alpha=1.0),
    "Lasso Regression": Lasso(alpha=0.1),
    "ElasticNet": ElasticNet(alpha=0.1),
    "Huber Regressor (Robust)": HuberRegressor(),
    "SVR (Support Vector)": SVR(kernel='rbf', C=100, gamma=0.1),
    "K-Neighbors Regressor": KNeighborsRegressor(n_neighbors=5),
    "Decision Tree": DecisionTreeRegressor(max_depth=10),
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
    "Extra Trees": ExtraTreesRegressor(n_estimators=100, random_state=42),
    "AdaBoost": AdaBoostRegressor(n_estimators=100, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(n_estimators=100, random_state=42)
}

selected_model_name = st.sidebar.selectbox("í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”", list(model_dict.keys()))
model = model_dict[selected_model_name]

# 3. ë°ì´í„° ë¡œë“œ ë° ë¬¼ë¦¬ ë³€í™˜
uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="csv")

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    df.columns = [col.strip() for col in df.columns]
    
    if 'ì¸¡ì • ì‹œê°„' in df.columns:
        df['ì¸¡ì • ì‹œê°„'] = pd.to_datetime(df['ì¸¡ì • ì‹œê°„'])
    
    # [ë¬¼ë¦¬ ë³€í™˜]
    df['Resistance_kOhm'] = df['ì €í•­'] / 1000.0
    df['Temp_K'] = df['ì˜¨ë„'] + 273.15
    p_sat = 6.112 * np.exp((17.62 * df['ì˜¨ë„']) / (243.12 + df['ì˜¨ë„']))
    df['Humidity_ppm'] = ((df['ìŠµë„'] / 100) * p_sat / 1013.25) * 1_000_000
    
    X = df[['Temp_K', 'Humidity_ppm']]
    y = df['Resistance_kOhm']
    
    # 4. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
    with st.spinner(f'{selected_model_name} í•™ìŠµ ì¤‘...'):
        model.fit(X, y)
        y_pred = model.predict(X)
        r2 = r2_score(y, y_pred)
        rmse = np.sqrt(mean_squared_error(y, y_pred))

    # 5. ë¦¬í¬íŠ¸ ì„¹ì…˜
    st.divider()
    col_rep1, col_rep2 = st.columns([1.5, 1])
    
    with col_rep1:
        st.subheader(f"ğŸ“ {selected_model_name} ë¶„ì„ ê²°ê³¼")
        
        # ì„ í˜• ê³„ìˆ˜ê°€ ìˆëŠ” ëª¨ë¸ (Linear, Ridge, Lasso, Huber ë“±)
        if hasattr(model, 'coef_'):
            coef = model.coef_.flatten()
            intercept = model.intercept_
            st.info(f"**ê³µì‹:** $R(k\Omega) = {intercept:.2f} + ({coef[0]:.4f} \\times T_K) + ({coef[1]:.6f} \\times H_{{ppm}})$")
        
        # ì¤‘ìš”ë„ íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ” ëª¨ë¸ (Tree ê¸°ë°˜ ì•™ìƒë¸”)
        elif hasattr(model, 'feature_importances_'):
            feat_imp = pd.Series(model.feature_importances_, index=['Temp(K)', 'Humidity(ppm)'])
            fig_imp, ax_imp = plt.subplots(figsize=(5, 2))
            feat_imp.sort_values().plot(kind='barh', color=['#3498db', '#e74c3c'], ax=ax_imp)
            ax_imp.set_title("Feature Importance", fontsize=10)
            st.pyplot(fig_imp)
        
        # ê·¸ ì™¸ ëª¨ë¸ (SVR, KNN ë“±)
        else:
            st.warning("ì´ ëª¨ë¸ì€ ëª…ì‹œì ì¸ ìˆ˜ì‹ì´ë‚˜ í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ì œê³µí•˜ì§€ ì•ŠëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.")

    with col_rep2:
        st.subheader("ğŸ¯ ëª¨ë¸ ì˜ˆì¸¡ ì„±ëŠ¥")
        st.metric("ê²°ì •ê³„ìˆ˜ (RÂ²)", f"{r2:.4f}")
        st.metric("í‰ê·  ì˜¤ì°¨ (RMSE)", f"{rmse:.4f} kÎ©")

    # 6. ì‹œê°í™” ì„¹ì…˜
    st.divider()
    st.header("ğŸ“ˆ ì˜ˆì¸¡ ì„±ëŠ¥ ì‹œê°í™”")
    
    plt.rcdefaults()
    sns.set_theme(style="whitegrid")
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # [ì¢Œì¸¡] Measured vs Predicted (ì„ í˜•ì„± í™•ì¸)
    axes[0].scatter(y, y_pred, alpha=0.2, s=2, color='darkblue')
    axes[0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)
    axes[0].set_title(f"Measured vs Predicted (R2={r2:.4f})")
    axes[0].set_xlabel("Measured (kOhm)")
    axes[0].set_ylabel("Predicted (kOhm)")

    # [ìš°ì¸¡] Residuals (ì˜¤ì°¨ ë¶„í¬) - ëª¨ë¸ì˜ ê±´ê°• ìƒíƒœ í™•ì¸
    residuals = y - y_pred
    sns.histplot(residuals, kde=True, ax=axes[1], color='purple')
    axes[1].set_title("Residuals Distribution (Error)")
    axes[1].set_xlabel("Error (kOhm)")

    st.pyplot(fig)

    # 7. ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (ë²„íŠ¼ í´ë¦­ ì‹œ)
    if st.sidebar.button("ğŸ† ì „ ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„ ë³´ê¸°"):
        st.divider()
        st.header("ğŸ† ì „ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ìˆœìœ„")
        results = []
        with st.spinner('ì „ì²´ ëª¨ë¸ ë²¤ì¹˜ë§ˆí‚¹ ì¤‘...'):
            for name, m in model_dict.items():
                m.fit(X, y)
                p = m.predict(X)
                results.append({
                    "Model": name,
                    "RÂ² Score": r2_score(y, p),
                    "RMSE (kÎ©)": np.sqrt(mean_squared_error(y, p))
                })
        res_df = pd.DataFrame(results).sort_values(by="RÂ² Score", ascending=False)
        st.table(res_df)

else:
    st.info("ğŸ‘‹ ì„¼ì„œ ë°ì´í„° CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë²¤ì¹˜ë§ˆí‚¹ì„ ì‹œì‘í•˜ì„¸ìš”.")