import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# ì‚¬ì´í‚·ëŸ° ëª¨ë¸ ì„í¬íŠ¸
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, HuberRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score, mean_squared_error

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Sensor ML Expert Pro", layout="wide")

# ëª¨ë¸ ì„¤ëª… ë°ì´í„°ë² ì´ìŠ¤ (ë²¤ì¹˜ë§ˆí‚¹ìš©)
model_info = {
    "Linear Regression": {
        "desc": "ê°€ì¥ ê¸°ë³¸ì ì¸ ëª¨ë¸ë¡œ, ì˜¨ë„/ë†ë„ì™€ ì €í•­ì´ ì§ì„  ê´€ê³„ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.",
        "pros": "ê³„ì‚°ì´ ë¹ ë¥´ê³  ìˆ˜ì‹($y=ax+b$)ì´ ëª…í™•í•´ ë¬¼ë¦¬ì  í•´ì„ì´ ê°€ì¥ ì‰½ìŠµë‹ˆë‹¤.",
        "cons": "ë³µì¡í•œ ë¹„ì„ í˜• ë°ì´í„°(ê³¡ì„  ë“±)ëŠ” ì˜ ë§ì¶”ì§€ ëª»í•©ë‹ˆë‹¤.",
        "best_for": "ê¸°ë³¸ ë³´ì •ì‹ ì‚°ì¶œìš©"
    },
    "Ridge Regression": {
        "desc": "ì„ í˜• íšŒê·€ì— 'ê·œì œ'ë¥¼ ë”í•´ ëª¨ë¸ì´ ë„ˆë¬´ ë³µì¡í•´ì§€ëŠ” ê²ƒì„ ë§‰ìŠµë‹ˆë‹¤.",
        "pros": "ë°ì´í„°ì— ë…¸ì´ì¦ˆê°€ ë§ì„ ë•Œ ì„ í˜• íšŒê·€ë³´ë‹¤ ì•ˆì •ì ì…ë‹ˆë‹¤.",
        "cons": "ì—¬ì „íˆ ì§ì„ ì ì¸ ê´€ê³„ë§Œ í•™ìŠµ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
        "best_for": "ë°ì´í„°ê°€ ì ê³  ë…¸ì´ì¦ˆê°€ ìˆì„ ë•Œ"
    },
    "Lasso Regression": {
        "desc": "ì¤‘ìš”í•˜ì§€ ì•Šì€ ë³€ìˆ˜ì˜ ì˜í–¥ë ¥ì„ 0ìœ¼ë¡œ ë§Œë“¤ì–´ë²„ë¦¬ëŠ” ê·œì œ ëª¨ë¸ì…ë‹ˆë‹¤.",
        "pros": "ë³€ìˆ˜ê°€ ë§ì„ ë•Œ ì •ë§ ì¤‘ìš”í•œ ë³€ìˆ˜ê°€ ë¬´ì—‡ì¸ì§€ ê±¸ëŸ¬ë‚´ê¸° ì¢‹ìŠµë‹ˆë‹¤.",
        "cons": "ë³€ìˆ˜ê°€ ì ì€ ê²½ìš° ì¼ë°˜ ì„ í˜• ëª¨ë¸ê³¼ í° ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤.",
        "best_for": "ë³€ìˆ˜ ì„ íƒ ë° ê°„ì†Œí™”"
    },
    "ElasticNet": {
        "desc": "Ridgeì™€ Lassoì˜ ì¥ì ì„ í•©ì¹œ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì…ë‹ˆë‹¤.",
        "pros": "ì—¬ëŸ¬ ë³€ìˆ˜ê°€ ì„œë¡œ ì–½í˜€ ìˆì„ ë•Œ(ë‹¤ì¤‘ê³µì„ ì„±) íš¨ê³¼ì ì…ë‹ˆë‹¤.",
        "cons": "ì„¤ì •í•´ì•¼ í•  íŒŒë¼ë¯¸í„°ê°€ ë§ì•„ ë‹¤ë£¨ê¸° ê¹Œë‹¤ë¡­ìŠµë‹ˆë‹¤.",
        "best_for": "ë³µí•©ì ì¸ í™˜ê²½ ë³€ìˆ˜ ì²˜ë¦¬"
    },
    "Huber Regressor (Robust)": {
        "desc": "ì´ìƒì¹˜(íŠ€ëŠ” ê°’)ì— ë§¤ìš° ê°•í•œ ì„ í˜• ëª¨ë¸ì…ë‹ˆë‹¤.",
        "pros": "ì„¼ì„œ ë…¸ì´ì¦ˆë‚˜ ì¼ì‹œì  íŠ€ëŠ” ê°’ì— íœ˜ë‘˜ë¦¬ì§€ ì•Šê³  ëŒ€ì„¸ ìˆ˜ì‹ì„ ì°¾ìŠµë‹ˆë‹¤.",
        "cons": "ë°ì´í„° ì „ì²´ê°€ ê¹¨ë—í•˜ë‹¤ë©´ ì¼ë°˜ ì„ í˜• ëª¨ë¸ë³´ë‹¤ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "best_for": "ì „ê¸°ì  ë…¸ì´ì¦ˆê°€ ì‹¬í•œ ë°ì´í„°"
    },
    "SVR (Support Vector)": {
        "desc": "ë°ì´í„°ë¥¼ ê³ ì°¨ì›ìœ¼ë¡œ ë³´ë‚´ ë³µì¡í•œ ê²½ê³„ì„ ì„ ì°¾ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.",
        "pros": "ë¹„ì„ í˜•ì ì¸ ì„¼ì„œ ë°˜ì‘ì„ ë§¤ìš° ì •êµí•˜ê²Œ ì¡ì•„ëƒ…ë‹ˆë‹¤.",
        "cons": "ë°ì´í„° ì–‘ì´ ë„ˆë¬´ ë§ìœ¼ë©´ í•™ìŠµ ì†ë„ê°€ ê¸‰ê²©íˆ ëŠë ¤ì§‘ë‹ˆë‹¤.",
        "best_for": "ì •ë°€í•œ ë¹„ì„ í˜• ë³´ì •"
    },
    "K-Neighbors Regressor": {
        "desc": "í˜„ì¬ ì¡°ê±´ê³¼ ê°€ì¥ ë¹„ìŠ·í•œ ê³¼ê±° ë°ì´í„° nê°œë¥¼ ì°¾ì•„ í‰ê· ì„ ëƒ…ë‹ˆë‹¤.",
        "pros": "ë°ì´í„° ë¶„í¬ë¥¼ ëª°ë¼ë„ ì§ê´€ì ìœ¼ë¡œ ì˜ ë§ì¶¥ë‹ˆë‹¤.",
        "cons": "ìˆ˜ì‹ì´ ë‚˜ì˜¤ì§€ ì•Šì•„ í•˜ë“œì›¨ì–´ ì´ì‹ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.",
        "best_for": "ë‹¨ìˆœ ì˜ˆì¸¡ ë° ì„±ëŠ¥ ë¹„êµ"
    },
    "Decision Tree": {
        "desc": "ìŠ¤ë¬´ê³ ê°œ ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ì—¬ ì˜ˆì¸¡í•©ë‹ˆë‹¤.",
        "pros": "ë°ì´í„°ì˜ íë¦„ì„ ì‹œê°ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ë§¤ìš° ì‰½ìŠµë‹ˆë‹¤.",
        "cons": "ê³¼ì í•©(Overfitting)ë˜ê¸° ì‰¬ì›Œ ìƒˆë¡œìš´ ë°ì´í„°ì— ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "best_for": "ë°ì´í„° ê·œì¹™ì„± íŒŒì•…"
    },
    "Random Forest": {
        "desc": "ìˆ˜ë§ì€ ê²°ì • ë‚˜ë¬´ë¥¼ ë§Œë“¤ì–´ ì§‘ë‹¨ì§€ì„±ìœ¼ë¡œ ê²°ê³¼ë¥¼ ëƒ…ë‹ˆë‹¤.",
        "pros": "ëŒ€ë¶€ë¶„ì˜ ì„¼ì„œ ë°ì´í„°ì—ì„œ ê°€ì¥ ì•ˆì •ì ì´ê³  ë†’ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.",
        "cons": "ëª¨ë¸ì˜ ìš©ëŸ‰ì´ í¬ê³  ë‚´ë¶€ ì—°ì‚° ê³¼ì •ì„ ì´í•´í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.",
        "best_for": "ë²”ìš©ì ì¸ ê³ ì„±ëŠ¥ ë¶„ì„"
    },
    "Extra Trees": {
        "desc": "Random Forestë³´ë‹¤ ë” ë¬´ì‘ìœ„ì„±ì„ ë¶€ì—¬í•´ ì†ë„ë¥¼ ë†’ì¸ ëª¨ë¸ì…ë‹ˆë‹¤.",
        "pros": "ì´ìƒì¹˜ì— ë” ê°•í•˜ê³  Random Forestë³´ë‹¤ ê³„ì‚°ì´ ë¹ ë¦…ë‹ˆë‹¤.",
        "cons": "ë•Œë•Œë¡œ Random Forestë³´ë‹¤ ì˜¤ì°¨ê°€ í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "best_for": "ë¹ ë¥´ê³  ê°•ê±´í•œ ì•™ìƒë¸” í•™ìŠµ"
    },
    "AdaBoost": {
        "desc": "ì•½í•œ ëª¨ë¸ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ í•™ìŠµì‹œì¼œ ì´ì „ì˜ ì‹¤ìˆ˜ë¥¼ ë³´ì™„í•©ë‹ˆë‹¤.",
        "pros": "ë‹¨ìˆœí•œ ëª¨ë¸ë“¤ì„ ëª¨ì•„ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ëŒì–´ëƒ…ë‹ˆë‹¤.",
        "cons": "ë…¸ì´ì¦ˆê°€ ë„ˆë¬´ ì‹¬í•˜ë©´ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ë§ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "best_for": "ë‹¨ê³„ì  ì˜¤ì°¨ ìˆ˜ì •"
    },
    "Gradient Boosting": {
        "desc": "í˜„ì¬ ê°€ì¥ ë„ë¦¬ ì“°ì´ëŠ” ê°•ë ¥í•œ ë¶€ìŠ¤íŒ… ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.",
        "pros": "ì˜ˆì¸¡ ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ í¸ì— ì†í•©ë‹ˆë‹¤.",
        "cons": "í•™ìŠµ ì‹œê°„ì´ ê¸¸ê³  íŒŒë¼ë¯¸í„° íŠœë‹ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.",
        "best_for": "ì •í™•ë„ ìµœìš°ì„  ì‹œ"
    }
}

# --- ì‚¬ì´ë“œë°” êµ¬ì„± ---
st.sidebar.title("ğŸ› ï¸ ë¶„ì„ ì„¤ì •")
app_mode = st.sidebar.radio("ë¶„ì„ ê¸°ëŠ¥ ì„ íƒ", ["1. ì „ ëª¨ë¸ ë²¤ì¹˜ë§ˆí‚¹", "2. ë…¸í™” ì§„ë‹¨ ë° ë¯¸ë˜ ì˜ˆì¸¡"])

st.sidebar.divider()
st.sidebar.header("ğŸ“ ë°ì´í„° ì†ŒìŠ¤")
data_source = st.sidebar.radio("ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ", ["GitHub ê¸°ë³¸ ë°ì´í„° (19.csv)", "ì‚¬ìš©ì íŒŒì¼ ì—…ë¡œë“œ"])

# --- GitHub ë°ì´í„° URL ì„¤ì • ---
GITHUB_CSV_URL = "https://raw.githubusercontent.com/yksskyts/tsei-temp-humi-R/refs/heads/main/19.csv"

# --- 1. ë°ì´í„° ë¡œë”© ì„¹ì…˜ ---
st.title("ğŸ§ª ì„¼ì„œ ì •ë°€ ë¶„ì„ ë° ë…¸í™” ì§„ë‹¨ ì‹œìŠ¤í…œ")

df = None

if data_source == "GitHub ê¸°ë³¸ ë°ì´í„° (19.csv)":
    try:
        df = pd.read_csv(GITHUB_CSV_URL)
        st.success(f"âœ… GitHubì—ì„œ '19.csv' ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"âŒ GitHub ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì‚¬ìœ : {e})")
else:
    uploaded_file = st.file_uploader("ë¶„ì„í•  CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="csv")
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)

# ë°ì´í„°ê°€ ì¡´ì¬í•  ê²½ìš°ì—ë§Œ ì´í•˜ ë¡œì§ ì‹¤í–‰
if df is not None:
    # ì»¬ëŸ¼ ê³µë°± ì œê±° ë° ê¸°ë³¸ ì „ì²˜ë¦¬
    df.columns = [col.strip() for col in df.columns]
    
    # ê³µí†µ ë¬¼ë¦¬ ë³€í™˜
    df['Resistance_kOhm'] = df['ì €í•­'] / 1000.0
    
    # ì‹œê°„ ê¸°ë°˜ 'ê²½ê³¼ ì¼ìˆ˜(Elapsed_Days)' ìƒì„±
    if 'ì¸¡ì • ì‹œê°„' in df.columns:
        df['ì¸¡ì • ì‹œê°„'] = pd.to_datetime(df['ì¸¡ì • ì‹œê°„'])
        first_time = df['ì¸¡ì • ì‹œê°„'].min()
        df['Elapsed_Days'] = (df['ì¸¡ì • ì‹œê°„'] - first_time).dt.total_seconds() / (24 * 3600)
    else:
        # ì‹œê°„ ì»¬ëŸ¼ ì—†ì„ ì‹œ í–‰ ì¸ë±ìŠ¤ ê¸°ë°˜ ìƒì„±
        df['Elapsed_Days'] = np.arange(len(df)) / (60 * 24)

    # ë²¤ì¹˜ë§ˆí‚¹ìš© ë¬¼ë¦¬ ë³€ìˆ˜ (PPM ë³€í™˜)
    p_sat = 6.112 * np.exp((17.62 * df['ì˜¨ë„']) / (243.12 + df['ì˜¨ë„']))
    df['Humidity_ppm'] = ((df['ìŠµë„'] / 100) * p_sat / 1013.25) * 1_000_000
    df['Temp_K'] = df['ì˜¨ë„'] + 273.15

    # ---------------------------------------------------------
    # MODE 1: ì „ ëª¨ë¸ ë²¤ì¹˜ë§ˆí‚¹
    # ---------------------------------------------------------
    if app_mode == "1. ì „ ëª¨ë¸ ë²¤ì¹˜ë§ˆí‚¹":
        st.sidebar.divider()
        st.sidebar.header("ğŸ¤– ëª¨ë¸ ì„¤ì •")
        selected_model_name = st.sidebar.selectbox("í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ", list(model_info.keys()))

        with st.sidebar.expander("ğŸ’¡ ëª¨ë¸ íŠ¹ì„±", expanded=True):
            info = model_info[selected_model_name]
            st.write(f"**ì„¤ëª…:** {info['desc']}")
            st.write(f"âœ… **ì¥ì :** {info['pros']}")
            st.write(f"âŒ **ë‹¨ì :** {info['cons']}")
            st.info(f"ğŸ¯ **ì¶”ì²œ:** {info['best_for']}")

        # ëª¨ë¸ ê°ì²´ ë§µí•‘
        model_dict = {
            "Linear Regression": LinearRegression(),
            "Ridge Regression": Ridge(alpha=1.0),
            "Lasso Regression": Lasso(alpha=0.1),
            "ElasticNet": ElasticNet(alpha=0.1),
            "Huber Regressor (Robust)": HuberRegressor(),
            "SVR (Support Vector)": SVR(kernel='rbf', C=100, gamma=0.1),
            "K-Neighbors Regressor": KNeighborsRegressor(n_neighbors=5),
            "Decision Tree": DecisionTreeRegressor(max_depth=10),
            "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
            "Extra Trees": ExtraTreesRegressor(n_estimators=100, random_state=42),
            "AdaBoost": AdaBoostRegressor(n_estimators=100, random_state=42),
            "Gradient Boosting": GradientBoostingRegressor(n_estimators=100, random_state=42)
        }
        
        model = model_dict[selected_model_name]
        X = df[['Temp_K', 'Humidity_ppm']]
        y = df['Resistance_kOhm']
        
        with st.spinner(f'{selected_model_name} ë¶„ì„ ì¤‘...'):
            model.fit(X, y)
            y_pred = model.predict(X)
            r2 = r2_score(y, y_pred)
            rmse = np.sqrt(mean_squared_error(y, y_pred))

        st.divider()
        col1, col2 = st.columns([1.5, 1])
        with col1:
            st.subheader(f"ğŸ“ {selected_model_name} ê²°ê³¼ ë³´ê³ ì„œ")
            if hasattr(model, 'coef_'):
                coef = model.coef_.flatten()
                st.info(f"**ë³´ì • ê³µì‹:** $R(k\Omega) = {model.intercept_:.2f} + ({coef[0]:.4f} \\times T_K) + ({coef[1]:.6f} \\times H_{{ppm}})$")
            elif hasattr(model, 'feature_importances_'):
                fig_imp, ax_imp = plt.subplots(figsize=(5, 2))
                pd.Series(model.feature_importances_, index=['Temp(K)', 'Humidity(ppm)']).sort_values().plot(kind='barh', color='#3498db', ax=ax_imp)
                ax_imp.set_title("Feature Importance")
                st.pyplot(fig_imp)
            else:
                st.warning("ì´ ëª¨ë¸ì€ í•´ì„ìš© ìˆ˜ì‹ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        with col2:
            st.subheader("ğŸ¯ ì„±ëŠ¥ ì§€í‘œ")
            st.metric("RÂ² Score (ì •í™•ë„)", f"{r2:.4f}")
            st.metric("RMSE (í‰ê·  ì˜¤ì°¨)", f"{rmse:.4f} kÎ©")

        st.divider()
        st.header("ğŸ“ˆ ì˜ˆì¸¡ ì„±ëŠ¥ ì‹œê°í™”")
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        sns.set_theme(style="whitegrid")
        axes[0].scatter(y, y_pred, alpha=0.2, s=2, color='darkblue')
        axes[0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)
        axes[0].set_title("Measured vs Predicted")
        sns.histplot(y - y_pred, kde=True, ax=axes[1], color='purple')
        axes[1].set_title("Error Distribution (Residuals)")
        st.pyplot(fig)

        if st.sidebar.button("ğŸ† ì „ì²´ ëª¨ë¸ ë­í‚¹ í™•ì¸"):
            st.divider()
            st.header("ğŸ† ì „ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ìˆœìœ„")
            results = []
            for name, m in model_dict.items():
                m.fit(X, y); p = m.predict(X)
                results.append({"Model": name, "RÂ²": r2_score(y, p), "RMSE": np.sqrt(mean_squared_error(y, p))})
            st.table(pd.DataFrame(results).sort_values(by="RÂ²", ascending=False))

    # ---------------------------------------------------------
    # MODE 2: ë…¸í™” ì§„ë‹¨ ë° ë¯¸ë˜ ì˜ˆì¸¡
    # ---------------------------------------------------------
    elif app_mode == "2. ë…¸í™” ì§„ë‹¨ ë° ë¯¸ë˜ ì˜ˆì¸¡":
        st.sidebar.divider()
        st.sidebar.header("ğŸ¤– ì•Œê³ ë¦¬ì¦˜ ì„¤ì •")
        model_choice = st.sidebar.selectbox("ì˜ˆì¸¡ ëª¨ë¸ ì„ íƒ", ["1. Linear Regression", "2. Ridge Regression", "3. Decision Tree", "4. Random Forest", "5. Gradient Boosting"])
        st.sidebar.warning("âš ï¸ ë¯¸ë˜ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ì€ 1, 2ë²ˆ ì„ í˜• ëª¨ë¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

        X_cols = ['ì˜¨ë„', 'ìŠµë„', 'Elapsed_Days']
        X = df[X_cols]
        y = df['Resistance_kOhm']
        
        if "1." in model_choice: model = LinearRegression()
        elif "2." in model_choice: model = Ridge(alpha=1.0)
        elif "3." in model_choice: model = DecisionTreeRegressor(max_depth=10)
        elif "4." in model_choice: model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)
        elif "5." in model_choice: model = GradientBoostingRegressor(n_estimators=50, random_state=42)

        with st.spinner('ë…¸í™” ë°ì´í„° ë¶„ì„ ì¤‘...'):
            model.fit(X, y)
            y_pred = model.predict(X)
            r2 = r2_score(y, y_pred)
            rmse = np.sqrt(mean_squared_error(y, y_pred))

        st.divider()
        col_a, col_b = st.columns([1.5, 1])
        with col_a:
            st.subheader("ğŸ“Š ì„¼ì„œ ë…¸í™”(Aging) ì§„ë‹¨")
            # ë…¸í™”ìœ¨ ê³„ì‚°ì„ ìœ„í•œ ë³„ë„ ì„ í˜• ë¶„ì„
            aging_model = LinearRegression().fit(X, y)
            drift = aging_model.coef_[2]
            if drift > 0:
                st.warning(f"âš ï¸ **ìƒíƒœ: ì €í•­ ìƒìŠ¹í˜• ì—´í™” ë°œìƒ**\n\ní•˜ë£¨ í‰ê·  **{drift:.4f} kÎ©**ì”© ì €í•­ê°’ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            else:
                st.success(f"âœ… **ìƒíƒœ: ì•ˆì •í™” ì§„í–‰ ì¤‘**\n\ní•˜ë£¨ í‰ê·  **{abs(drift):.4f} kÎ©**ì”© ì €í•­ì´ í•˜ê°•í•˜ë©° ì•ˆì •í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
            
            if hasattr(model, 'coef_'):
                st.info(f"**ë¬¼ë¦¬ ê³µì‹:** $R = {model.intercept_:.2f} + ({model.coef_[0]:.4f} \cdot T) + ({model.coef_[1]:.4f} \cdot H) + ({model.coef_[2]:.4f} \cdot Day)$")
            elif hasattr(model, 'feature_importances_'):
                fig_imp2, ax_imp2 = plt.subplots(figsize=(5, 2.2))
                pd.Series(model.feature_importances_, index=['Temp', 'Humi', 'Aging']).sort_values().plot(kind='barh', color='#2ecc71', ax=ax_imp2)
                ax_imp2.set_title("Variable Impact")
                st.pyplot(fig_imp2)

        with col_b:
            st.subheader("ğŸ¯ ì˜ˆì¸¡ ì •í™•ë„")
            st.metric("RÂ² (ê²°ì •ê³„ìˆ˜)", f"{r2:.4f}")
            st.metric("RMSE (ì˜¤ì°¨ ë²”ìœ„)", f"{rmse:.4f} kÎ©")

        st.divider()
        st.header("ğŸ”® ë¯¸ë˜ ê¸°ì € ì €í•­ ì˜ˆì¸¡")
        sc1, sc2, sc3, sr = st.columns([1, 1, 1, 2])
        with sc1: st_temp = st.number_input("ì„¤ì • ì˜¨ë„ (Â°C)", value=float(df['ì˜¨ë„'].mean()))
        with sc2: st_humi = st.number_input("ì„¤ì • ìŠµë„ (%)", value=float(df['ìŠµë„'].mean()))
        with sc3: st_days = st.number_input("ì¶”ê°€ ì‚¬ìš©ì¼ìˆ˜", value=30)
        
        future_day = df['Elapsed_Days'].max() + st_days
        future_pred = model.predict(pd.DataFrame([[st_temp, st_humi, future_day]], columns=X_cols))[0]
        with sr:
            st.metric(f"{st_days}ì¼ í›„ ì˜ˆìƒ ì €í•­", f"{future_pred:.4f} kÎ©")
            st.write(f"í˜„ì¬ ë§ˆì§€ë§‰ ì¸¡ì •ê°’ ëŒ€ë¹„ ë³€í™”ëŸ‰: **{future_pred - df['Resistance_kOhm'].iloc[-1]:+.4f} kÎ©**")

        st.divider()
        st.header("ğŸ“ˆ ë°ì´í„° ì‹œê°í™” ë¶„ì„")
        fig2, axes2 = plt.subplots(2, 2, figsize=(14, 10))
        sns.regplot(ax=axes2[0, 0], x='ì˜¨ë„', y='Resistance_kOhm', data=df, scatter_kws={'alpha': 0.05, 's': 1}, line_kws={'color': 'red'})
        axes2[0, 0].set_title("Temperature Impact")
        
        # ìˆœìˆ˜ ë“œë¦¬í”„íŠ¸ ì‹œê°í™”
        pure_drift = df['Resistance_kOhm'] - (aging_model.coef_[0]*df['ì˜¨ë„'] + aging_model.coef_[1]*df['ìŠµë„'] + aging_model.intercept_)
        axes2[0, 1].scatter(df['Elapsed_Days'], pure_drift, alpha=0.1, s=1, color='orange')
        axes2[0, 1].set_title("Pure Aging Drift (T/H Removed)")
        
        axes2[1, 0].scatter(y, y_pred, alpha=0.1, s=1, color='green')
        axes2[1, 0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
        axes2[1, 0].set_title("Model Linearity")
        
        sample = df.iloc[::20]
        axes2[1, 1].plot(sample['ì¸¡ì • ì‹œê°„'], sample['Resistance_kOhm'], label='Actual', alpha=0.6)
        axes2[1, 1].plot(sample['ì¸¡ì • ì‹œê°„'], y_pred[::20], label='ML', linestyle='--', color='lime')
        axes2[1, 1].legend()
        axes2[1, 1].set_title("Time-series Tracking")
        plt.tight_layout()
        st.pyplot(fig2)

    st.divider()
    st.download_button("ğŸ“‚ ë¶„ì„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", df.to_csv(index=False).encode('utf-8'), "sensor_analysis.csv")

else:
    st.info("ğŸ‘‹ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤. GitHub URLì„ í™•ì¸í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")git push origin main