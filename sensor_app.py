import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_squared_error

# 1. í˜ì´ì§€ ì„¤ì • ë° ì œëª©
st.set_page_config(page_title="Sensor ML Expert", layout="wide")
st.title("ğŸ§ª ì„¼ì„œ ì •ë°€ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Optimized)")
st.markdown("5ê°€ì§€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë¹„êµ ë¶„ì„í•˜ê³  ì‹¤ì‹œê°„ ì €í•­ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# 2. ì‚¬ì´ë“œë°” ëª¨ë¸ ì„ íƒ
st.sidebar.header("ğŸ¤– ëª¨ë¸ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ")
model_choice = st.sidebar.selectbox(
    "ì ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
    [
        "1. ì„ í˜• íšŒê·€ (Linear Regression)", 
        "2. ë¦¿ì§€ íšŒê·€ (Ridge Regression)", 
        "3. ì˜ì‚¬ê²°ì • ë‚˜ë¬´ (Decision Tree)", 
        "4. ëœë¤ í¬ë ˆìŠ¤íŠ¸ (Random Forest)", 
        "5. ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… (Gradient Boosting)"
    ]
)

# 3. ë°ì´í„° ë¡œë“œ
uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—¬ê¸°ì— ë“œë˜ê·¸í•˜ì„¸ìš”", type="csv")

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    df.columns = [col.strip() for col in df.columns]
    if 'ì¸¡ì • ì‹œê°„' in df.columns:
        df['ì¸¡ì • ì‹œê°„'] = pd.to_datetime(df['ì¸¡ì • ì‹œê°„'])
    df['Resistance_kOhm'] = df['ì €í•­'] / 1000.0
    
    X = df[['ì˜¨ë„', 'ìŠµë„']]
    y = df['Resistance_kOhm']
    
    # ëª¨ë¸ í• ë‹¹
    if "1." in model_choice: model = LinearRegression()
    elif "2." in model_choice: model = Ridge(alpha=1.0)
    elif "3." in model_choice: model = DecisionTreeRegressor(max_depth=10)
    elif "4." in model_choice: model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)
    elif "5." in model_choice: model = GradientBoostingRegressor(n_estimators=50, random_state=42)

    # ëª¨ë¸ í•™ìŠµ
    with st.spinner(f'{model_choice} ë¶„ì„ ì¤‘...'):
        model.fit(X, y)
    
    y_pred = model.predict(X)
    r2 = r2_score(y, y_pred)
    rmse = np.sqrt(mean_squared_error(y, y_pred))

    # 4. ë¶„ì„ ë¦¬í¬íŠ¸ (ìˆ˜ì‹/ì¤‘ìš”ë„ + ì„±ëŠ¥ ì§€í‘œ)
    st.divider()
    col_rep1, col_rep2 = st.columns([1.5, 1])
    
    with col_rep1:
        # ì„ í˜• ëª¨ë¸ ìˆ˜ì‹ ì¶œë ¥
        if hasattr(model, 'coef_'):
            st.subheader("ğŸ“ Regression Formula")
            st.info(f"**$R(k\Omega) = {model.intercept_:.2f} + ({model.coef_[0]:.4f} \\times T) + ({model.coef_[1]:.4f} \\times H)$**")
        # ë¹„ì„ í˜• ëª¨ë¸ ë³€ìˆ˜ ì¤‘ìš”ë„ ì¶œë ¥
        elif hasattr(model, 'feature_importances_'):
            st.subheader("ğŸ’¡ Feature Importance (Relative Impact)")
            feat_imp = pd.Series(model.feature_importances_, index=['Temp', 'Humi'])
            plt.rcdefaults() # ì˜ë¬¸ í°íŠ¸ ê°•ì œ
            fig_imp, ax_imp = plt.subplots(figsize=(5, 2.2)) # í¬ê¸° ì¶•ì†Œ
            feat_imp.sort_values().plot(kind='barh', color=['#3498db', '#e74c3c'], ax=ax_imp)
            ax_imp.set_title("Feature Importance Analysis (Tree-based)", fontsize=9)
            st.pyplot(fig_imp)

    with col_rep2:
        st.subheader("ğŸ¯ Model Performance")
        st.metric("ê²°ì •ê³„ìˆ˜ (RÂ²)", f"{r2:.4f}")
        st.metric("í‰ê·  ì˜¤ì°¨ (RMSE)", f"{rmse:.4f} kÎ©")

    # 5. ì‹¤ì‹œê°„ ì €í•­ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´í„°
    st.divider()
    st.header("ğŸ” ì‹¤ì‹œê°„ ì €í•­ ì˜ˆì¸¡")
    c_in1, c_in2, c_res = st.columns([1, 1, 2])
    with c_in1:
        input_temp = st.number_input("í˜„ì¬ ì˜¨ë„ (Â°C)", value=float(df['ì˜¨ë„'].mean()))
    with c_in2:
        input_humi = st.number_input("í˜„ì¬ ìŠµë„ (%)", value=float(df['ìŠµë„'].mean()))
    
    pred_val = model.predict([[input_temp, input_humi]])[0]
    with c_res:
        st.metric(f"ì˜ˆì¸¡ ì €í•­ê°’ ({model_choice.split('. ')[1]})", f"{pred_val:.4f} kÎ©")

    # 6. ì˜í–¥ë„ ë¶„ì„ ê·¸ë˜í”„ (ì „ì²´ ì˜ë¬¸ ë ˆì´ë¸” ë° í¬ê¸° ìµœì í™”)
    st.divider()
    st.header("ğŸ“ˆ ìƒì„¸ ì‹œê°í™” ë¶„ì„ (Visual Analysis)")
    
    plt.rcdefaults()
    sns.set_theme(style="whitegrid")
    fig, axes = plt.subplots(2, 2, figsize=(14, 10)) # í•œ í™”ë©´ì— ë“¤ì–´ì˜¤ë„ë¡ í¬ê¸° ì¡°ì •

    # [1] Temp vs Res
    sns.regplot(ax=axes[0, 0], x='ì˜¨ë„', y='Resistance_kOhm', data=df, 
                scatter_kws={'alpha': 0.02, 's': 1, 'color': 'gray'}, line_kws={'color': 'red'})
    axes[0, 0].set_title("Temperature vs Resistance", fontsize=12)
    axes[0, 0].set_xlabel("Temp (C)")
    axes[0, 0].set_ylabel("Res (kOhm)")

    # [2] Humi vs Res
    sns.regplot(ax=axes[0, 1], x='ìŠµë„', y='Resistance_kOhm', data=df, 
                scatter_kws={'alpha': 0.02, 's': 1, 'color': 'gray'}, line_kws={'color': 'blue'})
    axes[0, 1].set_title("Humidity vs Resistance", fontsize=12)
    axes[0, 1].set_xlabel("Humi (%)")
    axes[0, 1].set_ylabel("Res (kOhm)")

    # [3] Correlation
    axes[1, 0].scatter(y, y_pred, alpha=0.1, s=1, color='purple')
    axes[1, 0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=1.5)
    axes[1, 0].set_title(f"Model Linearity (R2={r2:.4f})", fontsize=12)
    axes[1, 0].set_xlabel("Measured (kOhm)")
    axes[1, 0].set_ylabel("Predicted (kOhm)")

    # [4] Time-series
    sample_df = df.iloc[::30]
    axes[1, 1].plot(sample_df['ì¸¡ì • ì‹œê°„'], sample_df['Resistance_kOhm'], label='Measured', alpha=0.5, color='black', lw=1)
    axes[1, 1].plot(sample_df['ì¸¡ì • ì‹œê°„'], y_pred[::30], label='Predicted', color='limegreen', linestyle='--', lw=1.5)
    axes[1, 1].set_title("Model Tracking Performance", fontsize=12)
    axes[1, 1].legend(prop={'size': 9})

    plt.tight_layout()
    st.pyplot(fig)

    # 7. ë‹¤ìš´ë¡œë“œ
    st.download_button("ê²°ê³¼ íŒŒì¼(CSV) ë‹¤ìš´ë¡œë“œ", df.to_csv(index=False).encode('utf-8'), "sensor_analysis.csv")

else:
    st.info("ğŸ‘‹ ì„¼ì„œ ë°ì´í„° CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")